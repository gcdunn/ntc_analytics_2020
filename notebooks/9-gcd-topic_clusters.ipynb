{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.matutils import sparse2full \n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models import TfidfModel, LdaModel\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim import corpora\n",
    "from gensim.utils import ClippedCorpus\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]*_')\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_db = '''/Data/samples/wiki/enwiki_articles_20200520.db'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query(query, db):\n",
    "    with sql.connect(db) as conn:\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "    df.columns = [str(col).lower() for col in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = '''SELECT * FROM articles LIMIT 1000'''\n",
    "df = get_query(sample, local_db)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, title in enumerate(df.title):\n",
    "    print(i, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus():\n",
    "    def __init__(self, row_ids, db, dictionary):\n",
    "        self.row_ids = row_ids\n",
    "        self.db = db\n",
    "        self.dictionary = dictionary\n",
    "        self.len = len(row_ids)\n",
    "\n",
    "    def __iter__(self):\n",
    "        row_ids_shuffled = np.random.choice(self.row_ids, self.len, replace=False)\n",
    "        with sql.connect(self.db) as conn:\n",
    "            for row_id in row_ids_shuffled:\n",
    "                select = '''SELECT text FROM articles where rowid=%d''' % row_id\n",
    "                doc = self.get_query(select, conn)\n",
    "                tokens = self.tokenize(doc)\n",
    "                out = self.dictionary.doc2bow(tokens)\n",
    "                yield out\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "        \n",
    "    def get_query(self, select, conn):\n",
    "        df = pd.read_sql_query(select, conn)\n",
    "        df.columns = [str(col).lower() for col in df.columns]\n",
    "        return df['text'].values[0]\n",
    "        \n",
    "    def tokenize(self, text):\n",
    "        text = REPLACE_BY_SPACE_RE.sub('', text)\n",
    "        text = text.lower()\n",
    "        text = ' '.join([word for word in text.split() if word not in STOPWORDS])\n",
    "        text = ' '.join([lemmatizer.lemmatize(word,'v') for word in text.split()])\n",
    "        tokens = re.findall('''[a-z-]{3,}''', text)\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowids = get_query('''SELECT rowid FROM articles''', local_db)['rowid'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, holdout_ids = train_test_split(rowids, train_size=0.8, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_dict = Dictionary().load('../output/holdout_set_wiki_dictionary_filtered.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = Dictionary().load('../output/train_set_wiki_dictionary_filtered.dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIFTY PERCENT TRAINING CORPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 TOPICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = LdaModel.load('../models/lda_50percent_corpus_100topics.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for t in range(ldamodel.num_topics):\n",
    "    plt.figure()\n",
    "    plt.imshow(WordCloud(background_color=\"white\").fit_words(dict(ldamodel.show_topic(t, 100))))\n",
    "    plt.axis(\"off\")\n",
    "    #plt.title(\"Topic #\" + str(t))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONE PERCENT TRAINING CORPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 TOPICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = LdaModel.load('../models/lda_1percent_corpus_100topics.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for t in range(ldamodel.num_topics):\n",
    "    plt.figure()\n",
    "    plt.imshow(WordCloud(background_color=\"white\").fit_words(dict(ldamodel.show_topic(t, 100))))\n",
    "    plt.axis(\"off\")\n",
    "    #plt.title(\"Topic #\" + str(t))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-wiki_topics]",
   "language": "python",
   "name": "conda-env-.conda-wiki_topics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
