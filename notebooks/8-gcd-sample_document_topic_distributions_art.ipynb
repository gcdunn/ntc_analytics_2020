{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.matutils import sparse2full \n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models import TfidfModel, LdaModel\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim import corpora\n",
    "from gensim.utils import ClippedCorpus\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]*_')\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_db = '''/Data/samples/wiki/enwiki_articles_20200520.db'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query(query, db):\n",
    "    with sql.connect(db) as conn:\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "    df.columns = [str(col).lower() for col in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_query = '''SELECT title FROM articles'''\n",
    "titles = get_query(title_query, local_db)\n",
    "titles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONE HUNDRED PERCENT TRAINING CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LdaModel.load('../models/new/lda_100percent_corpus_50topics.model')\n",
    "topics = pd.read_csv('../models/new/lda_100percent_corpus_50topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rowid = 100\n",
    "test_query = '''SELECT * FROM articles where rowid=%d''' % test_rowid\n",
    "test_article = get_query(test_query, local_db)\n",
    "test_tokens = next(iter(Corpus([test_rowid], local_db, holdout_dict)))\n",
    "test_topics = model[test_tokens]\n",
    "print(test_article.title.values[0])\n",
    "for topic in sorted(test_topics, key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print('Contribution:', np.round(topic[1],2), '    Topic:', [t.strip(\"''\") for t in topics.iloc[topic[0]].values[1].strip('][').split(', ')[:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIFTY PERCENT TRAINING CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LdaModel.load('../models/new/lda_50percent_corpus_50topics.model')\n",
    "topics = pd.read_csv('../models/new/lda_50percent_corpus_50topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rowid = 100\n",
    "test_query = '''SELECT * FROM articles where rowid=%d''' % test_rowid\n",
    "test_article = get_query(test_query, local_db)\n",
    "test_tokens = next(iter(Corpus([test_rowid], local_db, holdout_dict)))\n",
    "test_topics = model[test_tokens]\n",
    "print(test_article.title.values[0])\n",
    "for topic in sorted(test_topics, key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print('Contribution:', np.round(topic[1],2), '    Topic:', [t.strip(\"''\") for t in topics.iloc[topic[0]].values[1].strip('][').split(', ')[:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TWENTY FIVE PERCENT TRAINING CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LdaModel.load('../models/lda_25percent_corpus_50topics.model')\n",
    "topics = pd.read_csv('../models/lda_25percent_corpus_50topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rowid = 100\n",
    "test_query = '''SELECT * FROM articles where rowid=%d''' % test_rowid\n",
    "test_article = get_query(test_query, local_db)\n",
    "test_tokens = next(iter(Corpus([test_rowid], local_db, holdout_dict)))\n",
    "test_topics = model[test_tokens]\n",
    "print(test_article.title.values[0])\n",
    "for topic in sorted(test_topics, key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print('Contribution:', np.round(topic[1],2), '    Topic:', [t.strip(\"''\") for t in topics.iloc[topic[0]].values[1].strip('][').split(', ')[:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIVE PERCENT TRAINING CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LdaModel.load('../models/new/lda_5percent_corpus_50topics.model')\n",
    "topics = pd.read_csv('../models/new/lda_5percent_corpus_50topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rowid = 100\n",
    "test_query = '''SELECT * FROM articles where rowid=%d''' % test_rowid\n",
    "test_article = get_query(test_query, local_db)\n",
    "test_tokens = next(iter(Corpus([test_rowid], local_db, holdout_dict)))\n",
    "test_topics = model[test_tokens]\n",
    "print(test_article.title.values[0])\n",
    "for topic in sorted(test_topics, key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print('Contribution:', np.round(topic[1],2), '    Topic:', [t.strip(\"''\") for t in topics.iloc[topic[0]].values[1].strip('][').split(', ')[:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONE PERCENT TRAINING CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LdaModel.load('../models/new/lda_1percent_corpus_50topics.model')\n",
    "topics = pd.read_csv('../models/new/lda_1percent_corpus_50topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rowid = 100\n",
    "test_query = '''SELECT * FROM articles where rowid=%d''' % test_rowid\n",
    "test_article = get_query(test_query, local_db)\n",
    "test_tokens = next(iter(Corpus([test_rowid], local_db, holdout_dict)))\n",
    "test_topics = model[test_tokens]\n",
    "print(test_article.title.values[0])\n",
    "for topic in sorted(test_topics, key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print('Contribution:', np.round(topic[1],2), '    Topic:', [t.strip(\"''\") for t in topics.iloc[topic[0]].values[1].strip('][').split(', ')[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-wiki_topics]",
   "language": "python",
   "name": "conda-env-.conda-wiki_topics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
