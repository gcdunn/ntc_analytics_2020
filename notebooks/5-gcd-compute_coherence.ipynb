{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.matutils import sparse2full \n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models import TfidfModel, LdaModel\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim import corpora\n",
    "from gensim.utils import ClippedCorpus\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename='lda_model.log', format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_db = '''/Data/samples/wiki/enwiki_articles_20200520.db'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]*_')\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query(query, db):\n",
    "    with sql.connect(db) as conn:\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "    df.columns = [str(col).lower() for col in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = '''SELECT * FROM articles LIMIT 10'''\n",
    "df = get_query(sample, local_db)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text():\n",
    "    def __init__(self, row_ids, db):\n",
    "        self.row_ids = row_ids\n",
    "        self.db = db\n",
    "        self.len = len(row_ids)\n",
    "\n",
    "    def __iter__(self):\n",
    "        row_ids_shuffled = np.random.choice(self.row_ids, self.len, replace=False)\n",
    "        with sql.connect(self.db) as conn:\n",
    "            for row_id in row_ids_shuffled:\n",
    "                select = '''SELECT text FROM articles where rowid=%d''' % row_id\n",
    "                doc = self.get_query(select, conn)\n",
    "                tokens = self.tokenize(doc)\n",
    "                yield tokens\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "        \n",
    "    def get_query(self, select, conn):\n",
    "        df = pd.read_sql_query(select, conn)\n",
    "        df.columns = [str(col).lower() for col in df.columns]\n",
    "        return df['text'].values[0]\n",
    "        \n",
    "    def tokenize(self, text):\n",
    "        text = REPLACE_BY_SPACE_RE.sub('', text)\n",
    "        text = text.lower()\n",
    "        text = ' '.join([word for word in text.split() if word not in STOPWORDS])\n",
    "        text = ' '.join([lemmatizer.lemmatize(word,'v') for word in text.split()])\n",
    "        tokens = re.findall('''[a-z]{3,}''', text)\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowids = get_query('''SELECT rowid FROM articles''', local_db)['rowid'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, holdout_ids = train_test_split(rowids, train_size=0.8, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rowids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = Dictionary().load('../output/train_set_wiki_dictionary_filtered_no_hyphens.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_dict = Dictionary().load('../output/holdout_set_wiki_dictionary_filtered_no_hyphens.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(holdout_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_corpus = corpora.MmCorpus('/Data/Corpora/holdout_set_wiki_corpus_no_hyphens.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = corpora.MmCorpus('/Data/Corpora/train_set_wiki_corpus_no_hyphens.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = len(train_corpus)\n",
    "N_holdout = len(holdout_corpus)\n",
    "N_train, N_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_text = Text(holdout_ids, local_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = [50, 100, 250, 500]\n",
    "coherence_time_5percent = []\n",
    "coherence_val_5percent = []\n",
    "for k in num_topics:\n",
    "    print('--- Training on %s topics ---' % k)\n",
    "    start_time = time.time()\n",
    "    model = LdaModel.load('../models/lda_5percent_corpus_'+str(k)+'topics.model')    \n",
    "    topics = []\n",
    "    for topic_id, topic in model.show_topics(num_topics=k, num_words=100, formatted=False):\n",
    "        topic_words = [word for word, _ in topic]\n",
    "        topics.append(topic_words)  \n",
    "    coherence_model = CoherenceModel(topics=topics, texts=holdout_text, dictionary = holdout_dict, coherence='c_v')\n",
    "    coherence = coherence_model.get_coherence()\n",
    "    coherence_time = time.time()\n",
    "    coherence_minutes = round((coherence_time-start_time)/60.,2)\n",
    "    print('--- %s minutes to compute coherence ---' % coherence_minutes)\n",
    "    print('--- LDA %s topics coherence = %s ---' % (k, coherence))\n",
    "\n",
    "    coherence_time_5percent.append(coherence_minutes)\n",
    "    coherence_val_5percent.append(coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_time_5percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_val_5percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = [50, 100, 250, 500]\n",
    "coherence_time_10percent = []\n",
    "coherence_val_10percent = []\n",
    "for k in num_topics:\n",
    "    print('--- Training on %s topics ---' % k)\n",
    "    start_time = time.time()\n",
    "    model = LdaModel.load('../models/lda_10percent_corpus_'+str(k)+'topics.model')    \n",
    "    topics = []\n",
    "    for topic_id, topic in model.show_topics(num_topics=k, num_words=100, formatted=False):\n",
    "        topic_words = [word for word, _ in topic]\n",
    "        topics.append(topic_words)      \n",
    "    coherence_model = CoherenceModel(topics=topics, texts=holdout_text, dictionary = holdout_dict, coherence='c_v')\n",
    "    coherence = coherence_model.get_coherence()\n",
    "    coherence_time = time.time()\n",
    "    coherence_minutes = round((coherence_time-start_time)/60.,2)\n",
    "    print('--- %s minutes to compute coherence ---' % coherence_minutes)\n",
    "    print('--- LDA %s topics coherence = %s ---' % (k, coherence))\n",
    "\n",
    "    coherence_time_10percent.append(coherence_minutes)\n",
    "    coherence_val_10percent.append(coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_time_10percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_time_10percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = [50, 100, 250, 500]\n",
    "coherence_time_25percent = []\n",
    "coherence_val_25percent = []\n",
    "for k in num_topics:\n",
    "    print('--- Training on %s topics ---' % k)\n",
    "    start_time = time.time()\n",
    "    model = LdaModel.load('../models/lda_25percent_corpus_'+str(k)+'topics.model')    \n",
    "    coherence_model = CoherenceModel(topics=topics, texts=holdout_text, dictionary = holdout_dict, coherence='c_v')\n",
    "    topics = []\n",
    "    for topic_id, topic in model.show_topics(num_topics=k, num_words=100, formatted=False):\n",
    "        topic_words = [word for word, _ in topic]\n",
    "        topics.append(topic_words)\n",
    "    coherence_model = CoherenceModel(topics=topics, texts=holdout_text, dictionary = holdout_dict, coherence='c_v')\n",
    "    coherence = coherence_model.get_coherence()\n",
    "    coherence_time = time.time()\n",
    "    coherence_minutes = round((coherence_time-start_time)/60.,2)\n",
    "    print('--- %s minutes to compute coherence ---' % coherence_minutes)\n",
    "    print('--- LDA %s topics coherence = %s ---' % (k, coherence))\n",
    "\n",
    "    coherence_time_25percent.append(coherence_minutes)\n",
    "    coherence_val_25percent.append(coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_time_25percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_val_25percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = [50, 100, 250, 500]\n",
    "coherence_time_50percent = []\n",
    "coherence_val_50percent = []\n",
    "for k in num_topics:\n",
    "    print('--- Training on %s topics ---' % k)\n",
    "    start_time = time.time()\n",
    "    model = LdaModel.load('../models/lda_50percent_corpus_'+str(k)+'topics.model')\n",
    "    print('modle loaded...')\n",
    "    topics = []\n",
    "    for topic_id, topic in model.show_topics(num_topics=k, num_words=100, formatted=False):\n",
    "        topic_words = [word for word, _ in topic]\n",
    "        topics.append(topic_words)\n",
    "    print('topics collected...')\n",
    "    coherence_model = CoherenceModel(topics=topics, texts=holdout_text, dictionary = holdout_dict, coherence='c_v')\n",
    "    print('coherence model built...')\n",
    "    print('computing coherence...')\n",
    "    coherence = coherence_model.get_coherence()\n",
    "    coherence_time = time.time()\n",
    "    coherence_minutes = round((coherence_time-start_time)/60.,2)\n",
    "    print('--- %s minutes to compute coherence ---' % coherence_minutes)\n",
    "    print('--- LDA %s topics coherence = %s ---' % (k, coherence))\n",
    "\n",
    "    coherence_time_50percent.append(coherence_minutes)\n",
    "    coherence_val_50percent.append(coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_time_50percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_val_50percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = [50, 100, 250, 500]\n",
    "coherence_time_100percent = []\n",
    "coherence_val_100percent = []\n",
    "for k in num_topics:\n",
    "    print('--- Training on %s topics ---' % k)\n",
    "    start_time = time.time()\n",
    "    model = LdaModel.load('../models/lda_100percent_corpus_'+str(k)+'topics.model')  \n",
    "    print('model loaded...')\n",
    "    topics = []\n",
    "    for topic_id, topic in model.show_topics(num_topics=k, num_words=100, formatted=False):\n",
    "        topic_words = [word for word, _ in topic]\n",
    "        topics.append(topic_words)\n",
    "    print('topics collected...')\n",
    "    coherence_model = CoherenceModel(topics=topics, texts=holdout_text, dictionary = holdout_dict, coherence='c_v')\n",
    "    print('coherence model built...')\n",
    "    print('computing coherence...')\n",
    "    coherence = coherence_model.get_coherence()\n",
    "    coherence_time = time.time()\n",
    "    coherence_minutes = round((coherence_time-start_time)/60.,2)\n",
    "    print('--- %s minutes to compute coherence ---' % coherence_minutes)\n",
    "    print('--- LDA %s topics coherence = %s ---' % (k, coherence))\n",
    "\n",
    "    coherence_time_100percent.append(coherence_minutes)\n",
    "    coherence_val_100percent.append(coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_time_100percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_val_100percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-wiki_topics]",
   "language": "python",
   "name": "conda-env-.conda-wiki_topics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
